# Interpretable Explanations of Black Boxes by Meaningful Perturbation
## Presentation given to Drexel XAI seminar 11/18/2021

The presentation draws on the work proposed on a 2017 paper [Interpretable Explanations of Black Boxes by Meaningful Perturbation](https://arxiv.org/pdf/1704.03296.pdf) by [Ruth Fong](https://ruthcfong.github.io/) & [Andrea Vidaldi](https://www.robots.ox.ac.uk/~vedaldi/).  

**Repo for Paper:** https://github.com/ruthcfong/perturb_explanations 

### Suplemental works/blogs that helped me understand this paper: 

* ğŸ“– Simonyan, K., Vedaldi, A., & Zisserman, A. (2014). Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps. ArXiv:1312.6034 [Cs]. http://arxiv.org/abs/1312.6034
* ğŸ“º [How Deep Neural Networks Work](https://www.youtube.com/watch?v=ILsA4nyG7I0&t=1433s)
* ğŸ“ [Activation Functions in Neural Networks](https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6)
* ğŸ“ [What is Meta-Learning in Machine Learning](https://machinelearningmastery.com/meta-learning-in-machine-learning/)
* ğŸ“ [Understanding Neural Networks: From Activation Function To Back Propagation](https://medium.com/fintechexplained/neural-networks-activation-function-to-back-propagation-understanding-neural-networks-bdd036c3f29f)
* ğŸ“ [Understanding Neural Networks](https://towardsdatascience.com/understanding-neural-networks-19020b758230)
* ğŸ“º [Introduction to Optimization: Gradient Based Algorithms](https://www.youtube.com/watch?v=n-Y0SDSOfUI)
* ğŸ“˜ Molnar, Christoph. â€œInterpretable machine learning. A Guide for Making Black Box Models Explainableâ€, 2019, Chapter 10. https://christophm.github.io/interpretable-ml-book/.
* ğŸ“ [CNN Heat Maps: Gradients vs. DeconvNets vs. Guided Backpropagation](https://glassboxmedicine.com/2019/10/06/cnn-heat-maps-gradients-vs-deconvnets-vs-guided-backpropagation/#:~:text=In%20DeconvNets%2C%20at%20ReLUs%20only,backpropagation%2C%20except%20at%20the%20ReLUs.)
